{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:30:35.958013Z",
     "start_time": "2019-12-03T05:30:35.745830Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, CatBoostRegressor, cv\n",
    "def truncate(f, n):\n",
    "    return math.floor(f * 10 ** n) / 10 ** n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:30:44.643298Z",
     "start_time": "2019-12-03T05:30:37.856784Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:30:48.006710Z",
     "start_time": "2019-12-03T05:30:47.193903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples:  129971\n",
      "Number of examples with the same title and description:  9983\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of examples: \", data.shape[0])\n",
    "print(\"Number of examples with the same title and description: \",\n",
    "      data[data.duplicated(['description','title'])].shape[0])\n",
    "\n",
    "# Removing duplicate items\n",
    "data=data.drop_duplicates(['description','title'])\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:30:49.655742Z",
     "start_time": "2019-12-03T05:30:49.569720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping records with no price value as we don't want to include them in our model and dropping them won't affect the performance of our model\n",
    "data=data.dropna(subset=['price'])\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T06:14:58.649948Z",
     "start_time": "2019-12-02T06:14:58.513109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Substituting the NA values in other columns to UNKNOWN to that we can generate the one-hot-encoding correct\n",
    "data=data.fillna(\"UNKNOWN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:30:54.327608Z",
     "start_time": "2019-12-03T05:30:52.452967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the description to the lower case and removing non-alphabetic characters\n",
    "data['description']= data['description'].str.lower()\n",
    "data['description']= data['description'].apply(lambda elem: re.sub('[^a-zA-Z]',' ', elem))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:31:12.138527Z",
     "start_time": "2019-12-03T05:30:56.704076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4624968 words total, with a vocabulary size of 29486\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the description string, so that we can generate features using TF-IDF/Count vectorizer for regression\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words_descriptions = data['description'].apply(tokenizer.tokenize)\n",
    "words_descriptions.head()\n",
    "all_words = [word for tokens in words_descriptions for word in tokens]\n",
    "data['description_lengths']= [len(tokens) for tokens in words_descriptions]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:23.116539Z",
     "start_time": "2019-12-03T05:31:15.976780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing stop words and stemming\n",
    "stopword_list = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "words_descriptions = words_descriptions.apply(lambda elem: [word for word in elem if not word in stopword_list])\n",
    "words_descriptions = words_descriptions.apply(lambda elem: [ps.stem(word) for word in elem])\n",
    "data['description_cleaned'] = words_descriptions.apply(lambda elem: ' '.join(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:33:46.112474Z",
     "start_time": "2019-12-03T05:33:45.297584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2822364 words total, with a vocabulary size of 21073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wine', 69125),\n",
       " ('flavor', 62686),\n",
       " ('fruit', 53836),\n",
       " ('finish', 35863),\n",
       " ('aroma', 35564),\n",
       " ('palat', 33674),\n",
       " ('acid', 33330),\n",
       " ('cherri', 29505),\n",
       " ('drink', 28905),\n",
       " ('tannin', 27717),\n",
       " ('black', 24963),\n",
       " ('ripe', 24037),\n",
       " ('dri', 22844),\n",
       " ('note', 21892),\n",
       " ('spice', 20040),\n",
       " ('red', 18821),\n",
       " ('rich', 18382),\n",
       " ('fresh', 18095),\n",
       " ('berri', 16569),\n",
       " ('oak', 16557),\n",
       " ('show', 15940),\n",
       " ('nose', 14976),\n",
       " ('plum', 14252),\n",
       " ('sweet', 13919),\n",
       " ('full', 13729),\n",
       " ('offer', 13698),\n",
       " ('blackberri', 13395),\n",
       " ('textur', 13370),\n",
       " ('blend', 13280),\n",
       " ('appl', 13155),\n",
       " ('balanc', 13005),\n",
       " ('bodi', 13003),\n",
       " ('soft', 12045),\n",
       " ('age', 11719),\n",
       " ('crisp', 11409),\n",
       " ('well', 11328),\n",
       " ('white', 11150),\n",
       " ('light', 11149),\n",
       " ('dark', 10653),\n",
       " ('structur', 10643),\n",
       " ('citru', 10109),\n",
       " ('raspberri', 9909),\n",
       " ('cabernet', 9858),\n",
       " ('vanilla', 9829),\n",
       " ('hint', 9750),\n",
       " ('herb', 9717),\n",
       " ('miner', 9669),\n",
       " ('fruiti', 9653),\n",
       " ('bright', 9380),\n",
       " ('give', 9222),\n",
       " ('pepper', 9131),\n",
       " ('touch', 8885),\n",
       " ('lemon', 8666),\n",
       " ('year', 8657),\n",
       " ('green', 8655),\n",
       " ('good', 8557),\n",
       " ('juici', 8480),\n",
       " ('peach', 8287),\n",
       " ('feel', 8027),\n",
       " ('like', 7993),\n",
       " ('concentr', 7933),\n",
       " ('chocol', 7718),\n",
       " ('firm', 7696),\n",
       " ('pear', 7571),\n",
       " ('complex', 7535),\n",
       " ('currant', 7453),\n",
       " ('vineyard', 7405),\n",
       " ('toast', 7373),\n",
       " ('fine', 6890),\n",
       " ('come', 6858),\n",
       " ('sauvignon', 6857),\n",
       " ('open', 6794),\n",
       " ('charact', 6592),\n",
       " ('spici', 6558),\n",
       " ('pinot', 6445),\n",
       " ('smooth', 6412),\n",
       " ('tast', 6287),\n",
       " ('make', 6184),\n",
       " ('bottl', 6181),\n",
       " ('tart', 6126),\n",
       " ('made', 6114),\n",
       " ('style', 6110),\n",
       " ('eleg', 6029),\n",
       " ('medium', 6008),\n",
       " ('mouth', 5831),\n",
       " ('lead', 5827),\n",
       " ('round', 5789),\n",
       " ('intens', 5751),\n",
       " ('long', 5678),\n",
       " ('herbal', 5660),\n",
       " ('lime', 5605),\n",
       " ('tannic', 5534),\n",
       " ('wood', 5524),\n",
       " ('orang', 5408),\n",
       " ('merlot', 5371),\n",
       " ('bit', 5369),\n",
       " ('bake', 5336),\n",
       " ('also', 5308),\n",
       " ('creami', 5263),\n",
       " ('licoric', 5216)]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 100 common words (after cleaning)\n",
    "all_words = [word for tokens in words_descriptions for word in tokens]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\n",
    "count_all_words = Counter(all_words)\n",
    "count_all_words.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:36:24.887573Z",
     "start_time": "2019-12-03T05:36:24.883375Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataframe(vect, data, features=True):\n",
    "    vectorized=vect.fit_transform(data['description_cleaned']).toarray()\n",
    "    vectorized=pd.DataFrame(vectorized)\n",
    "    vectorized.columns = [ name + \"_nlp\" for name in  vect.get_feature_names()]\n",
    "    if features == True:\n",
    "        X=data.drop(columns=['points','Unnamed: 0','description','description_cleaned'])\n",
    "        X=X.fillna(-1)\n",
    "        print(X.columns)\n",
    "        X=pd.concat([X.reset_index(drop=True),vectorized.reset_index(drop=True)],axis=1)\n",
    "        categorical_features_indices =[0,1,3,4,5,6,7,8,9,10]\n",
    "    else:\n",
    "        X=vectorized\n",
    "        categorical_features_indices =[]\n",
    "    y=data['points']\n",
    "    return X,y,categorical_features_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Catboostregressor using the built in grid_search -- It takes a long time (2-3hrs) to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T22:53:10.466004Z",
     "start_time": "2019-12-02T22:52:55.623087Z"
    }
   },
   "outputs": [],
   "source": [
    "# I have commented out this code, as this tuning current runs for 2hrs, but this can be uncommented later, if needed to run\n",
    "# def hyperparamtuning(X_train, Y_train, categorical_features_indices):\n",
    "#     model = CatBoostRegressor(cat_features=categorical_features_indices, loss_function = 'RMSE')\n",
    "#     grid = {'learning_rate': [0.03, 0.02, 0.01],'depth': [4, 6, 10],'l2_leaf_reg': [1, 3, 5,]}\n",
    "#     search_results = model.grid_search(grid,X=X_train,y=Y_train,plot=True)\n",
    "#     return search_results\n",
    "\n",
    "# X, y , categorical_features_indices = prepare_dataframe(vect, data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "# hyperparamtuning_res = hyperparamtuning(X_train, y_train, categorical_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T22:40:52.520555Z",
     "start_time": "2019-12-02T22:40:52.514471Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Optimal parameters from hyperparam grid search:\", hyperparamtuning_res['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:36:35.035042Z",
     "start_time": "2019-12-03T05:36:35.008669Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_model(X_train, y_train,X_valid, y_valid,X_test, y_test,categorical_features_indices,name=\"TFIDF-based\", depth=6, learning_rate=0.03, l2_leaf_reg=1,\n",
    "                 optimal_param=True):\n",
    "    model = CatBoostRegressor(\n",
    "        random_seed = 100,\n",
    "        loss_function = 'RMSE',\n",
    "        iterations=800,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg = l2_leaf_reg\n",
    "     )\n",
    "    \n",
    "    if not optimal_param:\n",
    "        model = CatBoostRegressor(\n",
    "        random_seed = 100,\n",
    "        loss_function = 'RMSE',\n",
    "        iterations=800,\n",
    "     )\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features = categorical_features_indices,\n",
    "        verbose=False,\n",
    "        eval_set=(X_valid, y_valid)\n",
    "    )\n",
    "    \n",
    "#     print(name+\" technique RMSE on training data: \"+ model.score(X_train, y_train).astype(str))\n",
    "#     print(name+\" technique RMSE on test data: \"+ model.score(X_test, y_test).astype(str))\n",
    "    return model\n",
    "    \n",
    "def prepare_variable(vect, data, features_append=True):\n",
    "    X, y , categorical_features_indices = prepare_dataframe(vect, data,features_append)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, \n",
    "                                                        random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, \n",
    "                                                        random_state=52)\n",
    "    return X_train, y_train,X_valid, y_valid,X_test, y_test, categorical_features_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment this to plot the test-RMSE-mean vs iteration for hyper parameter grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T23:07:55.493507Z",
     "start_time": "2019-12-02T23:07:55.157073Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "# sns.set_style(\"dark\")\n",
    "# plt.style.use(['seaborn-darkgrid'])\n",
    "# plt.plot(hyperparamtuning_res['cv_results']['iterations'], np.log(hyperparamtuning_res['cv_results']['test-RMSE-mean']))\n",
    "# plt.title(\"Test-RMSE-MEAN over iterations\")\n",
    "# plt.xlabel(\"Iterations\")\n",
    "# plt.ylabel(\"log(test-RMSE-mean)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:41:15.740642Z",
     "start_time": "2019-12-03T05:37:58.851906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'designation', 'price', 'province', 'region_1', 'region_2',\n",
      "       'taster_name', 'taster_twitter_handle', 'title', 'variety', 'winery',\n",
      "       'description_lengths'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "vect= TfidfVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data)\n",
    "tfidf_model = perform_model(*training_variable, 'TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:41:46.554084Z",
     "start_time": "2019-12-03T05:41:46.304644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5594\n"
     ]
    }
   ],
   "source": [
    "x_test = training_variable[4]\n",
    "y_test = training_variable[5]\n",
    "pred = tfidf_model.predict(x_test)\n",
    "print(truncate(math.sqrt(mean_squared_error(pred, y_test)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:41:51.391866Z",
     "start_time": "2019-12-03T05:41:51.323900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>22.713024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>description_lengths</td>\n",
       "      <td>19.624077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>winery</td>\n",
       "      <td>7.864938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taster_name</td>\n",
       "      <td>6.812793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taster_twitter_handle</td>\n",
       "      <td>2.923642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rich_nlp</td>\n",
       "      <td>1.529884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>region_1</td>\n",
       "      <td>1.295969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beauti_nlp</td>\n",
       "      <td>1.208322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>complex_nlp</td>\n",
       "      <td>1.036663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lack_nlp</td>\n",
       "      <td>0.996292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>province</td>\n",
       "      <td>0.952118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature Id  Importances\n",
       "0                   price    22.713024\n",
       "1     description_lengths    19.624077\n",
       "2                  winery     7.864938\n",
       "3             taster_name     6.812793\n",
       "4   taster_twitter_handle     2.923642\n",
       "5                rich_nlp     1.529884\n",
       "6                region_1     1.295969\n",
       "7              beauti_nlp     1.208322\n",
       "8             complex_nlp     1.036663\n",
       "9                lack_nlp     0.996292\n",
       "10               province     0.952118"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_diff = tfidf_model.get_feature_importance(prettified=True)\n",
    "pred_diff[0:20]\n",
    "tfidf_model.get_feature_importance(prettified=True)[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:41:55.479536Z",
     "start_time": "2019-12-03T05:41:55.430955Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_model.save_model('tfidf_wine_points_prediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:45:09.651118Z",
     "start_time": "2019-12-03T05:41:59.538725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country', 'designation', 'price', 'province', 'region_1', 'region_2',\n",
      "       'taster_name', 'taster_twitter_handle', 'title', 'variety', 'winery',\n",
      "       'description_lengths'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "vect= TfidfVectorizer(analyzer='word', token_pattern=r'\\w+',max_features=500)\n",
    "training_variable=prepare_variable(vect, data)\n",
    "tfidf_model = perform_model(*training_variable, 'TF-IDF', optimal_param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:45:46.170026Z",
     "start_time": "2019-12-03T05:45:46.030335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5595\n"
     ]
    }
   ],
   "source": [
    "x_test = training_variable[4]\n",
    "y_test = training_variable[5]\n",
    "pred = tfidf_model.predict(x_test)\n",
    "print(truncate(math.sqrt(mean_squared_error(pred, y_test)), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
